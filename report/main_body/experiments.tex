\chapter{Πειραματική Μελέτη}

Στην παρούσα ενότητα παρουσιάζουμε τα αποτελέσματα των πειραμάτων που διενεργήθηκαν στην κάθε μια οικογένεια αλγορίθμων. Παρόλα αυτά, δεν είναι σκοπός η βελτιστοποίηση της απόδοσης (όπως καταγράφεται από τις επιλεγμένες μετρικές) για κάθε αλγόριθμο. Όπως έχουμε αναφέρει, ο σκοπός της παρούσας διπλωματικής είναι διττός: αφενός επιθυμούμε να εξερευνήσουμε την επίδραση της χαλάρωσης ορισμένων υποθέσεων των νευρωνικών δικτύων με κάψουλες στην απόδοσή τους (μέθοδος 1) και αφετέρου να επιλύσουμε το πρόβλημα της κλιμακωσιμότητας προτείνοντας έναν αποδοτικό αλγόριθμο δρομολόγησης (μέθοδος 3). Η τέταρτη, πολυδύναμη, μέθοδος, βρίσκεται στο μεταίχμιο αυτών με τη δυνατότητα τόσο για επιλεκτική χαλάρωση των περιορισμών της εν λόγω τεχνολογίας όσο για μερική βελτίωση του χρόνου εκπαίδευσης. Τέλος, η δεύτερη μέθοδος, λόγο της μεγάλης υπολογιστικής πολυπλοκότητάς της που δεν επέτρεπε τον εκτενή πειραματισμό, περιορίζεται σε δύο σύνολα δεδομένων και αναλαμβάνει τον σκοπό τις σύγκρισης με τις υπόλοιπες μεθόδους μας.\par

Όπως γίνεται αντιληπτό, κυρίως για τους αλγορίθμους της μεθόδου 1 αλλά και για αυτούς της μεθόδου 4, μας ενδιαφέρει περισσότερο η σχετική επίδοση μεταξύ αυτών αφού αυτή φανερώνει αν οι περιορισμοί που επιβάλλονται τελικά συμβάλουν στην καλύτερη γενίκευση του δικτύου ή όχι. Για τον λόγο αυτό, δίνουμε έμφαση στη σύγκριση των επιδόσεων μεταξύ των αλγορίθμων που ανήκουν στην ίδια οικογένεια (ίδια μέθοδο). Βέβαια, για λόγους πληρότητας, επιλέγουμε τους καλύτερους αλγορίθμους από την κάθε μέθοδο και τους συγκρίνουμε στο τέλος του παρόντος κεφαλαίου.\par

Κρίνεται σκόπιμο να αναφερθεί πως σε κάθε περίπτωση, η πειραματική μας μελέτη δεν είναι πλήρης. Ορισμένοι αλγόριθμοι που αναπτύξαμε (και ειδικά αυτοί που απαντώνται στην πολυδύναμη τέταρτη μέθοδο) διαμορφώνονται από μια πληθώρα υπερπαραμέτρων όπου η κάθε μια επιδρά καθοριστικά στην απόδοσή τους. Επιπρόσθετα, οι μειωμένοι υπολογιστικοί πόροι που διαθέτουμε καθιστούν τη διαδικασία πειραματισμού ιδιαιτέρως χρονοβόρα. Συνεπώς, είναι χρήσιμο να έχουμε υπ' όψη ότι οι επιδώσεις που καταγράφουμε πιθανότατα να επιδέχονται βελτίωση.\par

Το παρόν κεφάλαιο ακολουθεί την εξής διάρθρωση:
\begin{enumerate}
    \item Αρχικά γίνεται μια σύντομη παρουσίαση των συνόλων δεδομένων που χρησιμοποιούμε, των μετρικών αλλά και της πλατφόρμας πειραματισμού.
    \item Έπειτα ακολουθούν οι πειραματικές μελέτες της κάθε μεθόδου ξεχωριστά. Τα περιεχόμενα της κάθε τέτοιας υποενότητας διαφέρουν σημαντικά ανάλογα με τον σκοπό της εκάστοτε μεθόδου. Σε γενικές γραμμές όμως, περιλαμβάνουν τα αποτελέσματα που προκύπτουν από την αναζήτηση ικανοποιητικών υπερπαραμέτρων στα διάφορα σύνολα δεδομένων και τη σύγκριση των αλγορίθμων μεταξύ τους.
    \item Τέλος, επιλέγουμε τους καλύτερους αλγορίθμους από διαφορετικές μεθόδους και τους συγκρίνουμε μεταξύ τους αλλά και με άλλες υλοποιήσεις νευρωνικών δικτύων με κάψουλες που συναντώνται στη βιβλιογραφία.
\end{enumerate}

\section{Πλατφόρμα Διεξαγωγής Πειραμάτων, Μετρικές και Σύνολα Δεδομένων} 
Στην ενότητα αυτή κάνουμε λόγο για τα αμετάβλητα στοιχεία που συνθέτουν το περιβάλλον της πειραματικής μας μελέτης. Αυτά περιλαμβάνουν το υπολογιστικό σύστημα στο οποίο διενεργήθηκαν όλα τα πειράματα, τις μετρικές που χρησιμοποιήθηκαν για την εκτίμηση της επίδοσης και τα σύνολα δεδομένων με τα οποία οι αλγόριθμοι τροφοδοτήθηκαν.
\subsection{Πειραματική Πλατφόρμα}
Όλα τα πειράματα εκτελέστηκαν τοπικά, στον προσωπικό υπολογιστή (\en{PC}). Επειδή το σύστημα εκτέλεσης των πειραμάτων επηρεάζει τους χρόνους εκπαίδευσης, κρίνεται σκόπιμη η περιγραφή των δυνατοτήτων του υπολογιστικού μας συστήματος. Από πλευράς υλικού (\en{hardware}) λοιπόν, τα χαρακτηριστικά του είναι τα εξής:
\begin{itemize}
    \item 16GB \en{DDR4 RAM}
    \item \en{AMD Ryzen} 9 3900\en{X, 12-core CPU}
    \item \en{Nvidia RTX 2070 super GPU}
\end{itemize}

Ένα πολύ καλό εργαλείο για την αντιστοίχηση της υπολογιστικής δυνατότητας μιας συσκευής σε μια μετρική για την αντιπαραβολή με τις δυνατότητες άλλων συστημάτων είναι το \en{\it{ai-benchmark}}. Τρέχοντας το σχετικό πρόγραμμα εκτίμησης δυνατοτήτων, λάβαμε, μεταξύ άλλων τα παρακάτω αποτελέσματα:
\begin{itemize}
    \item \en{\it{Device Inference Score: 12150}}
    \item \en{\it{Device Training Score: 12115}}
    \item \en{\it{Device AI Score: 24265}}
\end{itemize}
Βέβαια, το περιβάλλον πειραματισμού απαρτίζεται και από τις εκδόσεις των πακέτων λογισμικού που είναι εγκατεστημένες στο σύστημα. Για αυτό τον σκοπό, στην \href{https://github.com/abarmper/Capsule_Nets_with_uncertainty}{ιστοσελίδα} όπου είναι αναρτημένος ο κώδικας, έχουμε καταγράψει όλα τα απαιτούμενα πακέτα λογισμικού. Ενδεικτικά, τα βασικότερα στοιχεία λογισμικού είναι τα εξής:
\begin{itemize}
    \item \en{Platform: \it{Linux}, Release: \it{5.15.0-48-generic}, Version: \it{20.04.1-Ubuntu}}
    \item \en{CUDA version: \it{11.0}}
    \item \en{cudnn version: \it{8}}
    \item \en{Tensorflow version: \it{2.4.1}}
    \item \en{Pytorch version: \it{1.7.1+cu110}}
\end{itemize}
Για να διευκολύνουμε την αναπαραγωγή πειραμάτων, ενσωματώνουμε και ένα εικονικό περιβάλλον (\en{Docker}). Το σχετικό αρχείο (\en{DockerFileGenericGPU}) δημιουργεί ένα εικονικό περιβάλλον με τις τα απαραίτητα πακέτα λογισμικού (\en{dependences}) που χρειάζεται να είναι εγκατεστημένα για την εκτέλεση των προγραμμάτων.
\subsection{Μετρικές Επίδοσης}

Λόγο του ερευνητικού χαρακτήρα της παρούσας διπλωματικής, μας ενδιαφέρει κυρίως η σύγκριση των μεθόδων μας με τις υπόλοιπες σχετικές μεθόδους που απαντώνται στη βιβλιογραφία. Για τον σκοπό αυτό και με δεδομένο ότι όλες οι εργασίες είναι εργασίες ταξινόμησης, η μετρική της ακρίβειας (\en{accuracy}) είναι η πλέον κατάλληλη μετρική. Η μετρική αυτή ορίζεται από τον λόγο των σωστά ταξινομημένων προβλέψεων προς το σύνολο των προβλέψεων. Με μαθηματικούς όρους δηλαδή, έχουμε:
\begin{equation}
    Accuracy = \frac{\text{\en{Number of Correct Predictions}}}{\text{\en{Total Number of Predictions}}}
\end{equation}
Ειδικά για το σύνολο δεδομένων \en{MultiMNIST} όπου έχουμε δύο προβλέψεις για κάθε δείγμα εισόδου, η μετρική μας ονομάζεται πολλαπλή\textendash Ακρίβεια (\en{multi-Accuracy}). Παρόλα αυτά, σύμφωνα με τον παραπάνω ορισμό (που εστιάζει στον αριθμό των προβλέψεων και όχι των δειγμάτων εισόδου) οι δύο μετρικές είναι ταυτόσημες.\par

Συχνά, αντί για την ακρίβεια, χρησιμοποιείται σαν μετρική το ποσοστιαίο σφάλμα ελέγχου (\en{test error rate\%}). Στην πραγματικότητα, δεν αποτελεί μια ξεχωριστή μετρική αφού ισχύει ότι $$test\_error\_rate = 100 - Accuracy*100\%.$$ \par

Όπως έχει γίνει αντιληπτό από το πρώτο κεφάλαιο της εργασίας, μας ενδιαφέρει να εντοπίσουμε μια αρχιτεκτονική με μικρό υπολογιστικό κόστος. Δύο μετρικές που φανερώνουν την ποσότητα αυτή είναι ο (σχετικός) μέσος χρόνος εκπαίδευσης ενός συνόλου δέσμης και ο αριθμός των εκπαιδευόμενων παραμέτρων ενός μοντέλου (των παραμέτρων δηλαδή που ρυθμίζονται με τον αλγόριθμο της οπισθοδιάδοσης σφάλματος). Συνεπώς, εκτός από την ακρίβεια, οι δύο αυτές μετρικές προστίθενται στα κριτήρια επιλογής των καλύτερων αλγορίθμων.

\subsection{Σύνολα Δεδομένων}
Στις περισσότερες μεθόδους μας χρησιμοποιούμε όλα τα σχετικά σύνολα δεδομένων με τα οποία δοκιμάζονται συνήθως οι αρχιτεκτονικές νευρωνικών δικτύων με κάψουλες. Γεγονός, που μας επιτρέπουν να εξετάσουμε αν τηρούνται οι χαρακτηριστικές ιδιότητες της εν λόγω τεχνολογίας από τα νέα μοντέλα που αναπτύξαμε. Τα σύνολα δεδομένων με τα οποία καταπιανόμαστε είναι τα \en{MNIST}\cite{deng2012mnist}, \en{FashionMNIST}\cite{Xiao2017FashionMNISTAN}, \en{CIFAR10}\cite{CIFAR10}, \en{MultiMNIST}\cite{sabour2017dynamic} και \en{smallNORB}\cite{lecun2004learning}. Για λόγους πληρότητας, στον πίνακα \ref{tab:exp_datasets} φαίνονται τα μοντέλα επιβλεπόμενης μάθησης που επιτυγχάνουν τη μέγιστη ακρίβεια για το κάθε σύνολο δεδομένων (καταγράφονται στην \href{https://paperswithcode.com/}{ιστοσελίδα} τον Οκτώβριο του 2022).


\begin{table}
    \begin{center}
        \en{
        \begin{tabular}{|c|c|c|} 
        \hline
        Dataset & Method & Test Error (\%) \\
        \hline \hline
         MNIST & Heterogeneous ensemble with simple CNN\cite{an2020ensemble} & 0.09 \\ 
         \hline
         FashionMNIST & Fine-Tuning DARTS\cite{tanveer2021fine} & 3.09 \\ 
         \hline
         CIFAR-10 & ViT-H/14\cite{dosovitskiy2020image_is_worth_16} & 0.5 \\ 
         \hline
         MultiMNIST & CapsNet\cite{sabour2017dynamic} & 5.2 \\ 
         \hline
         smallNORB & Heinsen Routing\cite{heinsen2019algorithm} & 0.90 \\ 
         \hline
        \end{tabular}
        }
        \end{center}
        \caption{\label{tab:exp_datasets} Πίνακας που συγκεντρώνει το καλύτερο μοντέλο και την απόδοσή του, για κάθε σύνολο δεδομένων.}
    \end{table}
    \subsubsection{Περιγραφή Συνόλων Δεδομένων \en{smallNORB} και \en{multiMNIST}}
    Τα δύο σύνολα δεδομένων είναι λιγότερο δημοφιλή στην ακαδημαϊκή κοινότητα για αυτό αφιερώνουμε αυτή την παράγραφο για την περιγραφή τους. Και τα δύο εξετάζουν την ιδιότητα των νευρωνικών δικτύων από κάψουλες να γενικεύουν σε νέες οπτικές γωνίες και να εξηγούν εικόνες με σημαντική επικάλυψη.\par

    Αναφορικά με το σύνολο δεδομένων \en{smallNORB}, αυτό περιέχει στερεο\textendash οπτικές εικόνες που απεικονίζουν 50 αντικείμενα (παιχνίδια) τα οποία ανήκουν σε 5 κλάσεις: τετράποδα ζώα, ανθρώπινες φιγούρες, αεροπλάνα, φορτηγά και αυτοκίνητα. Η κάθε κλάση εκπροσωπείται από δέκα φυσικά αντικείμενα, τα μισά εξ'αυτών βρίσκονται στο σύνολο εκπαίδευσης. Το σύνολο δεδομένων δημιουργήθηκε από την στερεοσκοπική λήψη αυτών των αντικειμένων από δύο κάμερες υπό 6 διαφορετικές συνθήκες φωτισμού, 9 διαφορετικά υψόμετρα προβολής (γωνίες 30◦έως 70◦ με βήμα 5◦) και 18 διαφορετικά αζιμούθια (γωνίες 0◦ έως 340◦ με βήμα 20◦). Έτσι, τόσο το σύνολο εκπαίδευσης όσο και το σύνολο ελέγχου αποτελούνται από 24.300 ζευγάρια στερεο\textendash πτικών εικόνων το καθένα. Οι αλγόριθμοί μας, δέχονται κάθε ζεύγος εικόνων σαν ένα δείγμα και στόχος τους είναι να προβλέψουν το απεικονιζόμενο αντικείμενο.\par

    Το σύνολο δεδομένων \en{multiMNIST} δημιουργήθηκε από τους \en{Hinton et al.} κατά την συγγραφή του έργου \cite{sabour2017dynamic}. Στην πραγματικότητα, ο αριθμός των δειγμάτων και τα περιεχόμενα του συνόλου δεν είναι προκαθορισμένα αφού η κάθε υλοποίηση κατασκευάζει δυναμικά το σύνολο αυτό λαμβάνοντας εικόνες από το σύνολο δεδομένων \en{MNIST} (αυτός είναι και ένας λόγος του περιορισμένου πειραματισμού με αυτό το σύνολο δεδομένων στη βιβλιογραφία). Ουσιαστικά, αποτελείται από εικόνες που απεικονίζουν στο ίδιο πλαίσιο, δύο επικαλυπτόμενα ψηφία (με ποσοστό επικάλυψης περίπου 80\%). Όπως είναι λογικό, κάθε ένα τέτοιο δείγμα συνοδεύεται από δύο ετικέτες: μια για κάθε απεικονιζόμενο ψηφίο.
    

\section{Πειραματική Μελέτη Μεθόδου 1}
\section{Πειραματική Μελέτη Μεθόδου 2}
\section{Πειραματική Μελέτη Μεθόδου 3}
\section{Πειραματική Μελέτη Μεθόδου 4}
\section{Σύγκριση Πειραματικών Αποτελεσμάτων Μεθόδων}