\chapter{Βιβλιογραφική Επισκόπηση}
\label{chap:related_work}

Πριν την έναρξη της εκπόνησης του πρακτικού τμήματος της παρούσας διπλωματικής πραγματοποιήθηκε βιβλιογραφική επισκόπηση προκειμένου να αναζητηθούν εργασίες σχετικές με το θέμα των νευρωνικών δικτύων με κάψουλες. Στο κεφάλαιο αυτό, θα γίνει αναφορά στις σημαντικότερες από αυτές οι οποίες λήφθηκαν υπόψην και ενέμπνευσαν τις μεθόδους που θα αναλύσουμε στο επόμενο κεφάλαιο.\par

Αρχικά, θα παρουσιάσουμε τις τρείς βασικές δημοσιεύσεις των \en{Hinton G. et al.} που θεμελίωσαν τη θεωρία πίσω από τα νευρωνικά δίκτυα με κάψουλες σε ένα πλαίσιο επιβλεπόμενης μάθησης. Έπειτα, θα αναφερθούμε στις ποικίλες παραλλαγές αυτών, όπως προκύπτουν από την τροποποίηση της αρχιτεκτονικής ή του αλγορίθμου δρομολόγησης. Στη συνέχεια, θα γίνει λόγος για τα νευρωνικά δίκτυα με κάψουλες σε περιβάλλον μη\textendash επιβλεπόμενης μάθησης. Τέλος, θα αναλυθούν συνοπτικά εργασίες οι οποίες επιλύουν αποτελεσματικά το γενικκότερο πρόβλημα της γενίκευσης σε νέες οπτικές γωνίες χρησιμοποιώντας αρχιτεκτονικές διαφορετικές από αυτή των νευρωνικών δικτύων με κάψουλες.\par

\section{Θεμελίωση Θεωρίας Νευρωνικών Δικτύων με Κάψουλες}

Όπως έχουμε αναφέρει, η ιδέα των νευρωνικών δικτύων με κάψουλες δεν είναι καινούρια αφού παρουσιάστηκε για πρώτη φορά από τους \en{Hinton G. et al.} το 2011. Παρόλα αυτά, σχετικά πρόσφατα, μετά από διαδοχικές δημοσιεύσεις, ωρίμασε και πέτυχε αξιοσημείωτα αποτελέσματα σε σύνολα δεδομένων όπως το \en{MultiMNIST}\cite{sabour2017dynamic}. Στην ενότητα αυτή θα κάνουμε λόγο για τα πρώτα τρία βασικά έργα πάνω στην εν λόγω αρχιτεκτονική τεχνητών νευρωνικών δικτύων. Πιο αναλυτικά, θα ξεκινήσουμε από τη δημοσίευση στην οποία πρωτοπαρουσιάστικε η ιδέα και θα καταλήξουμε στην πιο σύνθετη έκδοση των νευρωνικών δικτύων με κάψουλες για επιβλεπόμενη μάθηση που με τις επιδόσεις της στο σύνολο δεδομένων \en{smallNORB}\cite{lecun2004learning} κέντρισε το ενδιαφέρον των ερευνητών. 

\subsubsection{\en{Transforming Autoencoders}}

Στο έργο των \en{Hinton G. et al.}\footnote{Σε ελεύθερη μετάφραση: \textquote{Αυτο\textendash κωδικοποιητές Μετασχηματισμού}.} \cite{hinton2011transforming} παρουσιάζεται για πρώτη φορά η ιδέα των νευρωνικών δικτύων με κάψουλες. Η ιδέα απορρέει από την παρατήρηση ότι οι παρούσες μέθοδοι αναγνώρισης αντικειμένων σε εικόνες είναι ανεπαρκείς (για τους λόγους που αναφέραμε στην ενότητα \ref{sec:capsule_theory}). Έτσι, προκειμένου να γίνεται αποδοτικότερη αναγνώριση αντικειμένων (σε νέες οπτικές γωνίες), προτείνεται η αρχιτεκτονική του \textquote{αυτο\textendash κωδικοποιητή μετατροπέα} (\en{transforming auto\textendash encoder}). Η αρχιτεκτονική αυτή αποτελείται από ένα επίπεδο από \textquote{κάψουλες}, όπως φαίνεται στο σχήμα ...\footnote{Στην πρώιμη μορφή τους, οι κάψουλες διέφεραν από τη γενική μορφή που περιγράψαμε στην προηγούμενη ενότητα.}.\par

Κάθε κάψουλα αποτελείται από τις \textquote{μονάδες αναγνώρισης} (\en{recognition units}) οι οποίες παράγουν τις παραμέτρους στιγμιοτύπου καθώς και μια τιμή που συμβολίζει την πιθανότητα η οντότητα που αναγνωρίζει η κάψουλα να είναι παρούσα στο οπτικό της πεδίο (στο τμήμα της εικόνας εισόδου με το οποίο συνδέονται οι μονάδες αναγνώρισής της \textemdash στην περίπτωσή μας, σε ολόκληρη την εικόνα). Οι μονάδες παραγωγής είναι υπεύθυνες και για τον μετασχηματισμό από τον χώρο εικονοστοιχείων της εικόνας εισόδου σε έναν χώρο όπου οι μετασχηματισμοί οπτικής γωνίας (μετατόπισή, περιστροφή κ.α.) είναι γραμμικοί. Στη συνέχεια, κάθε κάψουλα τροφοδοτείται με τους καθολικούς (\en{global}) μετασχηματισμούς που συνδέουν την εικόνα εισόδου με την εικόνα εξόδου οι οποίοι εφαρμόζονται στις υπολογισμένες παραμέτρους. Έτσι, οι παράμετροι στιγμιοτύπου της κάθε κάψουλας πλέον εκφράζουν τις παραμέτρους στιγμιοτύπου του αντικειμένου εξόδου. Τέλος, η εικόνα ανακατασκευάζεται από τις μονάδες παραγωγής \en{generation units} τις οποίες κάθε κάψουλα διαθέτει. Αυτές ουσιαστικά διαβάζουν τις (μετασχηματισμένες) παραμέτρους στιγμιοτύπου και συνεισφέρουν στην ανακατασκευή της εικόνας εξόδου. Θεωρητικά, κάθε κάψουλα αναγνωρίζει ένα συγκεκριμένο τμήμα του αντικειμένου της εικόνας και όλες μαζί οι κάψουλες, συνθέτουν τα τμήματα που αναπαριστούν σιωπηρά (\en{implicitly}). Φυσικά, αν η τιμή πιθανότητας για μια κάψουλα είναι κοντά στο μηδέν, η συνεισφορά της θα είναι αμελητέα.\par

Ουσιαστικά, η αρχιτεκτονική του αυτο\textendash κωδικοποιητή που παρουσιάζεται πραγματοποιεί έναν μετασχηματισμό από τον χώρο των εικονοστοιχείων σε έναν χώρο αναπαράστασης όπου οι γεωμετρικοί μετασχηματισμοί περιγράφονται με γραμμικές σχέσεις. Στον χώρο αυτό εφαρμόζεται ένας γραμμικός μετασχηματισμός στις παραμέτρους της κάθε κάψουλας και έπειτα, οι παράμετροι αποκωδικοποιούνται πίσω στον χώρο των εικονοστοιχείων όπου και λαμβάνεται η μετασχηματισμένη εικόνα.\par

Στη δημοσίευση γίνονται πειράματα κυρίως στο σύνολο δεδομένων \en{MNIST}\cite{lecun1998gradientMNIST} για μικρές μετατοπίσεις των ψηφίων κατά τον $x$ και $y$ άξονα. Από αυτά τα πειράματα φαίνεται ότι οι παράμετροι σωστά εντοπίζουν τη θέση των αντικειμένων αλλά το οπτικό πεδίο της κάθε κάψουλας, μετά την εκπαίδευση, δεν είναι τοπικά προσδιορισμένο. Με άλλα λόγια, χρησιμοποιείται το σύνολο της εικόνας από τις μονάδες αναγνώρισης της κάθε κάψουλας για την εξαγωγή των παραμέτρων της. Επιπρόσθετα πειράματα έγιναν χρησιμοποιώντας το σύνολο δεδομένων \en{smallNORB}\cite{lecun2004learning} προκειμένου να διερευνηθεί η επίδοση της αρχιτεκτονικής σε σύνθετες μεταβολές της οπτικής γωνίας (\en{3-D Orientation}) που αναπαριστώνται με πίνακες $3\times3$. Για αυτό το σύνολο αυξήθηκε ο αριθμός των καψουλών του δικτύου και αυτές είχαν πεδίο υποδοχής που δεν κάλυπτε όλη την εικόνα. Όπως φαίνεται και στη δημοσίευση\cite{hinton2011transforming}, οι παραχθείσες εικόνες φαίνονται θολές.\par

Αν και το έργο που περιγράφουμε έχει ιδιαίτερη αξία αφού θεμελίωσε τις αρχές των νευρωνικών δικτύων με κάψουλες και διατύπωσε ορισμένα προβλήματά τους (π.χ. \en{crowding}), δεν μπορούσε να έχει πρακτική εφαρμογή λόγω της επίδοσής του στα σύνολα δεδομένων που δοκιμάστηκε. Επιπλέον, το γεγονός ότι για την εκπαίδευσή του, εκτός από τις εικόνες εισόδου και εξόδου έπρεπε να παρέχεται και η σχέση μεταξύ αυτών ήταν ένας ακόμη ανασταλτικός παράγοντας. Επιπρόσθετα, δεν παρείχε κάποιον ρητό τρόπο για την ανάθεση μερών του αντικειμένου σε αυτό. Όλα αυτά οδήγησαν σε απόπειρες βελτίωσης της αρχιτεκτονικής από το επόμενο έργο που θα παρουσιάσουμε. 

\subsubsection{\en{Dynamic Routing Between Capsules}}

Το έργο των \en{Sabour S. et al.}\footnote{Σε ελεύθερη μετάφραση: \textquote{Δυναμική Δρομολόγηση μεταύ Καψουλών}.} \cite{sabour2017dynamic} εξελίσσει την προηγούμενη μελέτη των νευρωνικών δικτύων με κάψουλες προτείνοντας έναν αλγόριθμο δρομολόγησης μέσω συμφωνίας. Με αυτόν, καθίσταται δυνατή η σύνθεση αντικειμένων από τα επιμέρους τμήματά του. Επιπλέον, αναθεωρεί τη δομή της κάψουλας η οποία πλέον είναι απόλυτα σύμφωνη με τον ορισμό που δώσαμε στην ενότητα \ref{sec:capsule_theory}. Δηλαδή, οι κάψουλες πλέον δεν αποτελούνται από δύο διαφορετικές ομάδες από τεχνητούς νευρώνες αλλά είναι ομάδες νευρώνων και η κάθε μια αναπαριστά ιδιότητες της συγκεκριμένης οντότητας που αναγνωρίζει. Οι ιδιότητες της αναγνωρισμένης οντότητας αναπαριστώνται με ένα διάνυσμα ενώ η βεβαιότητα αναγνώρισής της στην εικόνα εισόδου (η τιμή πιθανότητας) κωδικοποιείται στο μήκος του διανύσματος αυτού. Οι ανωτέρω βελτιώσεις, σε συνδυασμό με μια καινούρια αρχιτεκτονική είχαν σαν αποτέλεσμα βελτιωμένες (για την εποχή) επιδόσεις στο \en{MNIST}\cite{lecun1998gradientMNIST} και στο \en{MultiMNIST}\cite{sabour2017dynamic}.\par

Αναλυτικότερα για τη δομή του δικτύου από κάψουλες, αυτή αποτελείται από τρία επίπεδα τεχνητών νευρώνων. Το πρώτο είναι ένα κλασσικό συνελικτικό επίπεδο, όπως περιγράφηκε στην ενότητα \ref{sec:_cnn}. Το δεύτερο επίπεδο είναι και αυτό συνελικτικό και μαζί με το πρώτο αναλαμβάνουν τον ρόλο του μετασχηματισμού του χώρου των εικονοστοιχείων (χώρος εισόδου) σε έναν χώρο όπου οι νευρικές αποκρίσεις μεταβάλλονται γραμμικά καθώς αλλάζει η γωνία θέασης της εικόνας εισόδου. Στη συνέχεια, οι χάρτες χαρακτηριστικών (οι νευρικές αποκρίσεις) του δεύτερου συνελικτικού επιπέδου ομαδοποιούνται σε διανύσματα τα οποία και αποτελούν τις παραμέτρους στιγμιοτύπου του πρώτου επιπέδου από κάψουλες (\en{PrimaryCaps}). Μέσω της εκπαίδευσης, οι νευρώνες που προηγούνται των διανυσμάτων της κάθε κάψουλας δυνητικά μαθαίνουν να συσχετίζουν τις τιμές μεταξύ τους με τέτοιο τρόπο ώστε να αναπαριστούν ιδιότητες του ίδιου τμήματος αντικειμένου. Το τελευταίο επίπεδο είναι ένα επίπεδο από κάψουλες το οποίο αποτελεί και το επίπεδο εξόδου (ονομάζεται ως \en{DigitCaps}). Ο αριθμός των καψουλών στο επίπεδο εξόδου είναι τόσος όσος και ο αριθμός των κλάσεων ταξινόμησης\footnote{Σε μερικές εξαιρέσεις, χρησιμοποιείται μια παραπάνω κάψουλα εξόδου για την περίπτωση όπου το αντικείμενο εξόδου δεν ανήκει σε καμία από τις κλάσεις για τις οποίες το δίκτυο έχει εκπαιδευτεί να αναγνωρίζει.}. Τέλος, προαιρετικά προτείνεται η χρήση ενός αποκωδικοποιητή για την ανακατασκευή της αρχικής εικόνας με είσοδο το διάνυσμα της κάψουλας που εμπεριέχει το διάνυσμα ιδιοτήτων του αντικειμένου με το μεγαλύτερο μήκος (ονομάζεται διάνυσμα πρόβλεψης).\par

Για τη διαμόρφωση των διανυσμάτων του τελευταίου επιπέδου από κάψουλες (\en{DigitCaps}) χρησιμοποιείται ένας αλγόριθμος δρομολόγησης με συμφωνία του οποίου η βασική λειτουργία περιγράφηκε στην ενότητα \ref{sec:capsule_theory}. Συγκεκριμένα, με τον προτεινόμενο αλγόριθμο \textquote{Δυναμικής Δρομολόγησης μέσω Συμφωνίας} (\en{Dynamic Routing by Agreement}), οι κάψουλες του προηγούμενου επιπέδου παράγουν μια πρόβλεψη για τις παραμέτρους στιγμιοτύπου της κάθε κάψουλας του επόμενου επιπέδου. Τις προβλέψεις αυτές τις δρομολογούν στο επόμενο επίπεδο βεβαρημένες από τις \textquote{παραμέτρους σύζευξης} που προσαρμόζονται από τον εν λόγο αλγόριθμο. Όταν πολλές προβλέψεις συμφωνούν για τις παραμέτρους στιγμιοτύπου μιας κάψουλας, τότε με αυτόν τον τρόπο συνδιαμορφώνουν τις παραμέτρους της και αυτή αποκτά μεγάλη τιμή πιθανότητας (το διάνυσμά της έχει μεγάλο μέτρο). Μια ακόμα βελτίωση που οφείλεται στη χρήση αλγορίθμου δρομολόγησης είναι ότι σε αντίθεση με την προηγούμενη μέθοδο, πλέον δεν απαιτείται να παρέχεται κατά την εκπαίδευση κάποιος πίνακας μετασχηματισμού. Αντίθετα, το δίκτυο αποθηκεύει εσωτερικά πίνακες μετασχηματισμού οι οποίοι μαθαίνουν (μέσω εκπαίδευσης) να αναπαριστούν τις (ανεξάρτητες\textendash στιγμιοτύπου) σχέσεις τμημάτων - όλου.\par

Η δημοσίευση \en{Dynamic Routing Between Capsules} παρείχε υποσχόμενα πειραματικά αποτελέσματα. Πιο συγκεκριμένα, δοκιμάστικε στο σύνολο δεδομένων \en{MNIST}\cite{lecun1998gradientMNIST} όπου και είχε 0.25\% σφάλμα ελέγχου (\en{test error}) με μόλις 8.2\en{M} παραμέτρους. Για σύγκριση, ένα τυπικό \en{baseline} συνελικτικό δίκτυο πετυχαίνει 0.39\% σφάλμα ελέγχου (\en{test error}) με πολύ περισσότερες παραμέτρους (35.4\en{M}). Αξιοσημείωτες επιδόσεις παρατηρήθηκαν και στο \en{MultiMNIST}\cite{sabour2017dynamic} σύνολο δεδομένων το οποίο αποτελείται από αριθμούς με υψηλή επικάλυψη μεταξύ τους. Σε αυτό το σφάλμα ελέγχου ήταν 5.2\%, πολύ μικρότερο από αυτό του συνελικτικού μοντέλου (8.1\%). Επίσης, βέλτιστα (για την εποχή) αποτελέσματα παρατηρήθηκαν στα σύνολα δεδομένων \en{affNIST} και \en{smallNORB}. Ειδικά οι υψηλές επιδώσεις στο πρώτο σύνολο, όπου περιέχει ψηφία μετασχηματισμένα από διάφορους αφινικούς μετασχηματισμούς, αποδεικνύει την ευρωστία των δικτύων με κάψουλες σε μεταβολές της οπτικής γωνίας. Τέλος, το δίκτυο δοκιμάστηκε στο (σύνθετο) σύνολο δεδομένων CIFAR10 αλλά η επίδοσή του σε αυτό δεν ήταν εντυπωσιακή (10.6\% σφάλμα ελέγχου).

\subsubsection{\en{Matrix Capsules with EM Routing}}

Η επιστημονική μελέτη των \en{Hinton G. et al.}\footnote{Σε ελεύθερη μετάφραση: \textquote{Πινακοειδής Κάψουλες με Αλγόριθμο Δρομολόγησης Μεγιστοποίησης Προσδοκιών}.}\cite{hinton2018matrix} βελτιώνει την προηγούμενη υλοποίηση τροποποιώντας την αρχιτεκτονική του νευρωνικού δικτύου από κάψουλες (αυξάνοντας τον συνολικό αριθμό παραμέτρων) και προτείνοντας έναν νέο αλγόριθμο δρομολόγησης μέσω συμφωνία βασιζόμενο στον αλγόριθμο Μεγιστοποίησης Προσδοκιών (\en{Expectation Maximization}). \par

Πιο αναλυτικά, οι βασικότερες τροποποιήσεις της προηγούμενης μελέτης είναι οι εξής:
\begin{enumerate}
    \item Η κάθε κάψουλα διαθέτει ξεχωριστή λογιστική μονάδα (\en{logistic unit}) για την αναπαράσταση της πιθανότητας ύπαρξης της οντότητας που αναγνωρίζει. Αυτός ο τρόπος, σύμφωνα με τους \en{Hinton G. et al.}\cite{hinton2018matrix} είναι καλύτερος από τη κωδικοποίηση της τιμής πιθανότητας στο μήκος του διανύσματος παραμέτρων στιγμιοτύπου.
    \item Σαν μετρική ομοιότητάς μεταξύ των ψήφων χρησιμοποιείται ο αρνητικός λογάριθμος της διακύμανσης (\en{variance}) των Γκαυσσιανών συστάδων. Αυτή η μετρική ομοιότητας είναι καλύτερη από την ομοιότητα συνημιτόνου (\en{cosine similarity}) καθώς είναι πιο ευαίσθητη στη περιοχή υψηλής ομοιότητας\footnote{Με άλλα λόγια, μπορεί καλύτερα να διακρίνει μια σχετικά καλή ομοιότητα από μια άριστη ομοιότητα.}.
    \item Στην νέα μελέτη προτείνεται μια ελαφρώς τροποποιημένη δομή κάψουλας η οποία ενθυλακώνει τις παραμέτρους στιγμιοτύπου υπο τη μορφή πίνακα πόζας με $n$ στοιχεία. Αυτή η αλλαγή επιτρέπει στους πίνακες μετασχηματισμού να έχουν μέγεθος $n^2$ και όχι μόνο $n$.
    \item Εισάγεται μια νέα πολυεπίπεδη αρχιτεκτονική (βλ. σχήμα ....) η οποία περιλαμβάνει συνελικτικά επίπεδα από κάψουλες προκειμένου να διαμοιράζεται η γνώση (που αποθηκεύεται στη μορφή πινάκων μετασχηματισμού) στον χώρο.
\end{enumerate}\par

Με τα πειράματα που έγιναν στο προτεινόμενο μοντέλο μηχανικής μάθησης αποδεικνύεται η αποδοτικότερη αναγνώριση αντικειμένων όταν αυτά αναπαρίστανται σε εικόνες με διαφορετικές γωνίες λήψης. Για παράδειγμα, για το σύνολο δεδομένων \en{smallNORB} επιτυγχάνεται σφάλμα ελέγχου ίσο με 1.4\% (πολύ μικρότερο σε σχέση με το σφάλμα 5.2\% του βασικού μοντέλου - αποτελούμενου από συνελικτικά επίπεδα). Επιπλέον, υψηλές επιδόσεις παρατηρήθηκαν όταν δοκιμάστικε η προτεινόμενη αρχιτεκτονική νευρωνικού δικτύου με κάψουλες στο ίδιο σύνολο δεδομένων αλλά σε οπτικές γωνίες απεικονιζόμενων αντικειμένων που δεν είχε εκπαιδευτεί (\en{novel viewpoints}). Τέλος, το μοντέλο φάνηκε να είναι εύρωστο σε επιθέσεις τύπου λευκού\textendash κουτιού (\en{white\textendash box adversarial attacks})\cite{goodfellow2014explaining}\footnote{Έχει δειχθεί ότι δεν ισχύει το ίδιο για επιθέσεις τύπου μαύρου\textendash κουτιού (\en{black\textendash box adversarial attacks})}. 

\section{Παραλλαγές Νευρωνικών Δικτύων με Κάψουλες}

Στην ενότητα αυτή θα γίνει σύντομη αναφορά στις βασικότερες έρευνες που σχετίζονται άμεσα με τα νευρωνικά δίκτυα από κάψουλες σε περιβάλλον επιβλεπόμενης μάθησης. Οι έρευνες αυτές κυρίως εστιάζουν σε τροποποιήσεις του αλγορίθμου δρομολόγησης και της αρχιτεκτονικής του δικτύου. Ακόμα, περιλαμβάνονται ορισμένες εργασίες που πειραματίζονται εκτενώς με τις βασικές υλοποιήσεις, όπως τις περιγράψαμε παραπάνω.\par

Κατά τη διάρκεια της βιβλιογραφικής μελέτης των νευρωνικών δικτύων με κάψουλες απαιτείται να έχουμε υπ'όψη τα εξής κριτήρια:
\begin{itemize}
    \item Αν οι βασικές ιδιότητες που σχετίζονται με την αποδοτική διαχείριση των αντικειμένων υπό διαφορετικές οπτικές γωνίες διατηρούνται (π.χ. εύρωστες εσωτερικές αναπαραστάσεις που μεταβάλλονται ανάλογα με τις αλλαγές στην οπτική γωνία, δυνατότητα αποθήκευσης γνώσης ανεξάρτητη από τη γωνία θέασης κ.α.).
    \item Αν υπάρχουν αλλαγές στις υποθέσεις που αφορούν τις σχέσεις μέρους\textendashόλου.
    \item Αν οι κάψουλες ενεργοποιούνται μέσω πολυδιάστατης σύμπτωσης \en{high\textendash dimensional coincidences}
    \item Πώς διαχειρίζεται το προτεινόμενο σύστημα την εγγενή αβεβαιότητά της σύνθεσης ενός αντικειμένου από τα τμήματά του. \cite{de2020introducing}
\end{itemize}\par

Σημειώνουμε ότι στις βιβλιογραφικές μελέτες στις οποίες αναφερόμαστε παρακάτω αποφύγαμε να συμπεριλάβουμε τα έργα που παρουσιάζουν μεγάλες αποκλίσεις από τα βασικά κριτήρια των νευρωνικών δικτύων με κάψουλες.\par

\subsubsection{\en{Capsule Routing via Variational Bayes}}

Η εν λόγω μελέτη\footnote{Σε ελεύθερη μετάφραση: \textquote{Δρομολόγηση Καψουλών με Μπεϋζιανή Διακύμανση}.}\cite{De_Sousa_Ribeiro_Leontidis_Kollias_2020_Capsule_Routing} βασίζεται στην \cite{hinton2018matrix} και την βελτιώνει προτείνοντας έναν διαορετικό αλγόριθμο δρομολόγησης μέσω συμφωνίας. Πιο συγκεκριμένα, με τον αλγόριθμο δρομολόγησης βασισμένο στη συμπερασματολογία διακύμανσης (\en{Variational Inference}) - ονομάζεται δρομολόγηση μπεϋζιανής διακύμανσης (\en{Variational Bayed Routing}) είναι εφικτή η μοντελοποίηση αβεβαιότητας στις παραμέτρους της κάψουλας (εκτός από τους συντελεστές δρομολόγησης). Με αυτήν την πιθανοκρατική προσέγγιση, είναι εφικτή η τροποποίηση των πρότερων πιθανοτήτων της κάθε κάψουλας για καλύτερο έλεγχο της πολυπλοκότητάς τους και για αποφυγή του προβλήματος της κατάρρευσης διασποράς (\en{variance collapse}). Επιπλέον, δείχνουν τον τρόπο με τον οποίοι ένα νευρωνικό δίκτυο από κάψουλες μπορεί να μετατραπεί σε αυτο\textendash κωδικοποιητή διακύμανσης (\en{variational auto\textendash encoder}). Τέλος, παρέχουν μερικές οδηγίες για την εκπαίδευση του προτεινόμενου μοντέλου (αρχικοποίηση βαρών και σχέδια κανονικοποίησης). \par

Οι πειραματισμοί του προτεινόμενου μοντέλου στα σύνολα δεδομένων \en{smallNORB, SVHN, MNIST} και \en{affNIST} αποδεικνύουν την ισχυριζόμενη βελτίωση της βασικής υλοποίησης των νευρωνικών δικτύων με κάψουλες. Πιο αναλυτικά, στο σύνολο δεδομένων \en{smallNORB}\cite{lecun2004learning} επιτυγχάνεται μείωση του σφάλματος ελέγχου στην τιμή 1.55\% (σε αντίθεση με 1.8\% όπως προκύπτει από το \cite{hinton2018matrix}) χρησιμοποιώντας μόλις τον μισό αριθμό από κάψουλες. Βελτιωμένα αποτελέσματα παρατηρήθηκαν και στα υπόλοιπα σύνολα δεδομένων αλλά και σε πειράματα που δοκιμάζουν την ικανότητα γενίκευσης του δικτύου και την ευρωστία του σε αινικούς μετασχηματισμούς. Τέλος, αποδηκνύεται ότι ένα δίκτυο που χρησιμοποιεί τον προτεινόμενο αλγόριθμο συγκλίνει κατά 20\% γρηγορότερα, με αυξημένη αριθμητική ευσταθής.

\subsubsection{\en{Introducing Routing Uncertainty in Capsule Networks}}
Η επόμενη δημοσίευση που εξετάζουμε \footnote{Σε ελεύθερη μετάφραση: \textquote{Εισάγοντας Αβεβαιότητα Δρομολόγησης στα Νευρωνικά Δίκτυα από Κάψουλες}.}\cite{de2020introducing} τροποποιεί την προηγούμενη υλοποίηση ώστε να είναι πιο αποδοτική με βελτιωμένα πειραματικά αποτελέσματα. Αρχικά, εντοπίζει ορισμένα μειονεκτήματα των τοπικών, επαναλληπτικών αλγορίθμων δρομολόγησης τα οποία είναι:
\begin{itemize}
    \item Το υψηλό υπολογιστικό κόστος ενός επαναληπτικού, αλγορίθμου δρομολόγησης που λαβάνει χώρα μεταξύ δύο διαδοχικών επιπέδων από κάψουλες.
    \item Κατά τη δρομολόγηση της πληροφορίας από το ένα επίπεδο καψουλών στο επόμενο λαμβάνονται υπόψη μόνο τα τοπικά συμφραζόμενα (\en{local context}), δηλαδή η πληροφορία μεταξύ των δύο επιπέδων.
    \item Η τάση για υπερπροσαρμογή ή υποπροσαρμογή (\en{overfitting/underfitting}) ανάλογα με την επιλογή των αριθμών επανάληψης του αλγορίθμου δρομολόγησης (\en{routing iterations}).
\end{itemize}
Για τον σκοπό αυτό, προτείνεται η αντικατάσταση των τοπικών επαναλήψεων (\en{local iterations}) με μια \textquote{σφαιρική εικόνα} (\en{global view}) βασισμένη στην προσέγγιση της εκ των υστέρων πιθανότητας διακύμανσης (\en{variational posterior}) στις συνδέσεις μέρους - όλου σε ένα πιθανοκρατικό μοντέλο. Η χρήση καθολικών κρυφών μεταβλητών (\en{global latent variables}) που επηρεάζουν άμεσα την αντικειμενική συνάρτηση (\en{obective function}) προσδίδει στο  την ικανότητα για εποπτικότερη δρομολόγηση της πληροφορίας. Οι μεταβλητές αυτές ενημερώνονται μεροληπτικά (\en{discriminatively}) σύμφωνα με την αρχή του ελάχιστου μήκους περιγραφής (\en{minimum description length}) της θεωρίας πληροφορίας (\en{information theory}).\par

Τα εκτενή πειράματα στο σύνολο δεδομένων \en{smallNORB} αποδεικνύουν ότι ακόμα και με μικρότερο αριθμό παραμέτρων σε σχέση με τις προηγούμενες υλοποιήσεις των νευρωνικών δικτύων με κάψουλες, η επίδοση του δικτύου είναι ελαφρώς βελτιωμένη. Πολλά πειράματα επίσης διενεργήθηκαν με σκοπό να διασφαλιστεί ότι διατηρούνται οι βασικές ιδιότητες του εν λόγο είδους νευρωνικών δικτύων. Ενδεικτικά, εκτός από τα πειράματα στο σύνολο δεδομένων \en{smallNORB} και \en{MultiMNIST}, έγιναν πειράματα σχετικά με τη δυνατότητα γενίκευσης σε νέες οπτικές γωνίες, την ευρωστία σε αφινικούς μετασχηματισμούς των εικόνων εισόδου για τους οποίους το δίκτυο δεν έχει εκπαιδευτεί αλλά και την ικανότητά του να εκπαιδεύεται αποδοτικά με λίγα παραδείγματα (\en{Few\textendash Shot Learning}). Σε όλα τα πειράματα, οι επιδόσεις ήταν πλήρως ικανοποιητικές, αποδηκνείωντας έτσι ότι τηρούνται οι βασικές υποθέσεις των νευρωνικών δικτύων με κάψουλες.

\subsubsection{\en{Group Equivariant Capsule Networks}}

Το έργο των \en{Lenssen et al.} \footnote{Σε ελεύθερη μετάφραση: \textquote{Νευρωνικά Δίκτυα με Κάψουλες Ομάδας Ισοδύναμης Διακύμανσης}.} \cite{lenssen2018group} προτείνει ένα τροποποιημένο είδος από κάψουλες και έναν αλγόριθμο δρομολόγησης βασιζόμενα στη θεωρεία ομάδων. Προκύπτει, από τον συνδειασμό μελετών τόσο στο αντικείμενο των νευρωνικών δικτύων με κάψουλες όσο και στην μελέτη που εισήγαγε τα δίκτυα συνέλιξης ομάδας\cite{cohen2016group}. Με αυτόν τον τρόπο, το προτεινόμενο μοντέλο αποδεικνήεται ότι εγγυάται τις ιδιότητες της ανεξαρτησίας των παραμέτρων ενεργοποίησης των καψουλών και της ισοδύναμης διακύμανσης των παραμέτρων πόζας (ανάλογα με τις μεταβολές της οπτικής γωνίας του αντικειμένου εισόδου). Ιδιαίτερα ενδιαφέρον είναι ο τρόπος με τον οποίο δημιουργείται το πρώτο επίπεδο από κάψουλες (\en{primary capsules}). Αναλυτικότερα, δεν χρησιμοποιούνται κάποια προσαρμοζόμενα φίλτρα από τον αλγόριθμο εκπαίδευσης αλλά γίνεται χρήση των (στατικών) φίλτρων \en{Sobel}. Τα πειράματα περιορίστηκαν στο σύνολο δεδομένων \en{MNIST} όπου επιτεύχθηκε εκπληκτική ακρίβεια ταξινόμησης των ψηφίων (98.42\%) όταν αυτά είχαν περιστραφεί τυχαία με πολλαπλάσια των $90^{\circ}$ και ενώ το δίκτυο είχε εκπαιδευτεί με ψηφία χωρίς κανένα μετασχηματισμό.


\subsubsection{\en{CapsuleGAN: Generative Adversarial Capsule Network}}

Στην δημοσίευση των \en{Jaiswal et al.} \footnote{Σε ελεύθερη μετάφραση: \textquote{Παραγωγικό Αντιπαραθετικό Δίτκτυο με Κάψουλες}.}\cite{jaiswal2018capsulegan} εφαρμόζεται η αρχιτεκτονική του νευρωνικού δικτύου με κάψουλες, όπως παρουσιάζεται από τους \en{Sabour et al.}\cite{sabour2017dynamic} στο πλαίσιο των παραγωγικών, αντιπαραθετικών δικτύων. Συγκεκριμένα, πρόκειται περισσότερο για μια εφαρμογή που αντικαθίσταται το συνελικτικό δίκτυο διάκρισης (\en{convolutional descriminative network}) ενός παραγωγικού αντιπαραθετικού δικτύου (\en{Generative Adversarial Network}) με ένα δίκτυο διάκρισης από κάψουλες. Για την εκπαίδευση του δικτύου, χρησιμοποιούν μια συνάρτηση κόστους που προκαλεί το παιχνίδι αντιπαράθεσης (\en{adversarial game}) μεταξύ της γεννήτριας και του δικτύου διάκρισης, τροποποιημένη κατάλληλα για ένα δίκτυο διάκρισης από κάψουλες. Μέσα από τα πειράματα στα \en{MNIST} και \en{CIFAR10} σύνολα δεδομένων, προκύπτει ότι ένα Παραγωγικό Αντιπαραθετικό Δίτκτυο με Κάψουλες έχει καλύτερη επίδοση από ένα αντίστοιχο δίκτυο με αμιγώς συνελικτικά επίπεδα. Οι βελτιωμένες επιδόσεις εντοπίστηκαν στη μοντελοποίησης πιθανοτικής κατανομής των δεδομένων εικόνων (όπως προκύπτουν από τη μετρική παραγωγικής αντιπαράθεσης (\en{GAM})\cite{im2016generative} και από τα πειράματα ταξινόμησης εικόνων ημι\textendash επιβλεπόμενης μάθησης).

\subsubsection{\en{MS\textendash CapsNet: A Novel Multi\textendash Scale Capsule Network}}

Στη μελέτη των \en{Xiang et al.} \footnote{Σε ελεύθερη μετάφραση: \textquote{Ένα Νέο Πολυ\textendash Κλιμακωτό Νευρωνικό Δίκτυο με Κάψουλες}.} \cite{xiang2018ms} παρουσιάζεται μια νέα αρχιτεκτονική νευρωνικών δικτύων με κάψουλες που βελτιώνει την ικανότητα αναπαράστασης ιεραρχικής πληροφορίας από τις κάψουλες, μειώνοντας παράλληλα την υπολογιστική πολυπλοκότητα. Η ιδέα πίσω από αυτή την τροποποίηση είναι ότι εξάγγοντας πλουσιότερες αναπαραστάσεις, είναι δυνατή η βελτίωση της επίδοσης σε σύνθετα δεδομένα εισόδου. Επιπλέον, τροποποιείται η \textquote{τεχνική εγκατάλειψης} (\en{dropout}) προκειμένου να μπορεί να εφαρμοστεί σε ένα επίπεδο από κάψουλες. Τέλος, η αρχιτεκτονική δοκιμάζεται σε εργασίες ταξινόμησης στα σύνολα \en{FashionMNIST} και \en{CIFAR10} όπου παρατηρούνται βελτιωμένα αποτελέσματα (ακρίβεια 0.927 και 0.757 αντίστοιχα με λιγότερες από τις μισές παραμέτρους) σε αντιπαραβολή με την υλοποίηση \cite{sabour2017dynamic}.\par

Η αρχιτεκτονική του πρώτου και δεύτερου επιπέδου του δικτύου φαίνεται στο σχήμα ...  . Έπειτα ακολουθεί το τελευταίο επίπεδο από κάψουλες (παρόμοια με το έργο \cite{sabour2017dynamic}). Χωρίς να εμβαθύνουμε ιδιαίτερα, η εξαγωγή χαρακτηριστικών γίνεται πολυκλιμακωτά, με το πρώτο παρακλάδι να παράγει κωδικοποιήσεις σημασιολογικής πληροφορίας (πληροφορίας ανώτερης τάξης), το δεύτερο να παράγει διανύσματα που κωδικοποιούν πληροφορία μέσης τάξης και το τελευταίο, να έχει ως έξοδο τα ακατέργαστα χαρακτηριστικά. Τα εξαγόμενα χαρακτηριστικά οργανώνονται σε κάψουλες που εμπεριέχουν διανύσματα διαστατικότητας 12, 8 και 4 αντίστοιχα (ανάλογα με το παρακλάδι από το οποίο προκύπτουν). Τέλος, μέσω των πινάκων μετασχηματισμών $W, V, U$, παράγονται ψήφοι ίσου μεγέθους  $\hat{u^1_{j|i}}, \hat{u^2_{j|i}}, \hat{u^3_{j|i}}$ για κάθε ζεύγος $i \rightarrow j$ που συνδέονται σηρειακά (\en{concatenate}) σε ένα διάνυσμα $\hat{u_{j|i}} = concat(\hat{u^1_{j|i}}, \hat{u^2_{j|i}}, \hat{u^3_{j|i}})$.\par

Δυστυχώς, πέρα από τα προαναφερθέντα πειράματα, το δίκτυο δεν εξετάζεται κατά πόσον τηρεί τις θεμελιώδεις υποθέσεις των νευρωνικών δικτύων με κάψουλες. Επιπλέον, οι πίνακες $W, V, U$ δεν έχουν τετραγωνική μορφή με αποτέλεσμα να μην είναι αναστρέψιμοι (και κατά συνέπεια, ο μετασχηματισμός δεν είναι γεωμετρικός).

\subsubsection{\en{DDRM-CapsNet: Capsule Network Based on Deep Dynamic Routing Mechanism for Complex Data}}