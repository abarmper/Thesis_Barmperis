\chapter{Μέθοδος}
\label{chap:method}

Όπως αναφέραμε στο προηγούμενο κεφάλαιο, οι θεμελιακές υλοποιήσεις των νευρωνικών δικτύων από κάψουλες (\cite{hinton2011transforming, sabour2017dynamic, hinton2018matrix}) βασίζονται σε υποθέσεις των οποίων η εγκυρότητα δεν έχει δοκιμαστεί εκτενώς. Για τον λόγο αυτό (αλλά και για λόγους σύγκρισης με άλλες μεθόδους), δύο από τις τέσσερεις μεθόδους που χρησιμοποιούμε στο πειραματικό μέρος της παρούσας διπλωματικής αναπτύχθηκαν (ή τροποποιήθηκαν) σε πηγαίο κώδικα σύμφωνα με την αρχιτεκτονική και τον αλγόριθμο δρομολόγησης που παρουσιάζονται στα έργα \cite{sabour2017dynamic} και \cite{hinton2018matrix} αντίστοιχα. \par

Οι δύο τελευταίες μέθοδοί του παρόντος κεφαλαίου, πατώντας στις βασικές δομικές αρχές των νευρωνικών δικτύων με κάψουλες, επιδιώκουν να βελτιώσουν ορισμένες από τις ανεπάρκειες της τεχνολογίας. Έτσι, προτείνονται καινοτόμοι αλγόριθμοι και αρχιτεκτονικές νευρωνικών δικτύων που εστιάζουν είτε σε προβλήματα ταχύτητας και κλιμακωσιμότητας (τρίτη μέθοδος) είτε στα προβλήματα εγκυρότητας των αρχικών υποθέσεων (τέταρτη μέθοδος).


\section{\en{Dynamic Routing Between Capsules}}

Η μέθοδος της \textquote{Δυναμικής Δρομολόγησης με Κάψουλες} υλοποιήθηκε σε κώδικα ακολουθώντας πιστά την ομώνυμη δημοσίευση των \en{Sabour S. et al.} \cite{sabour2017dynamic}. Αν και υπήρχαν έτοιμες υλοποιήσεις του έργου στο διαδίκτυο, δυστυχώς ο κώδικάς τους ήταν αναχρονισμένος και δε λειτουργούσε σε σύγχρονα συστήματα με τις νέες εκδόσεις των πακέτων λογισμικού. Για αυτό και υλοποιήθηκε εκ νέου στη γλώσσα \en{python 3} χρησιμοποιώντας τη βιβλιοθήκη \en{tensorflow 2}. \par

Σε αυτήν την ενότητα θα ξεκινήσουμε παρουσιάζοντας τη γενική αρχιτεκτονική του νευρωνικού δικτύου με κάψουλες που προτείνει το εν λόγω έργο. Στη συνέχεια και σε ξεχωριστή υπο\textendash ενότητα θα παρουσιάσουμε τον αλγόριθμο δρομολόγησης που λαμβάνει χώρα μεταξύ των δυο διαδοχικών επιπέδων από κάψουλες. Έπειτα, θα αναφερθούμε στη συνάρτηση σφάλματος που χρησιμοποιείται για την εκπαίδευση του νευρωνικού δικτύου κάτω από τις διάφορες συνθήκες παραμετροποίησης. Τέλος, θα γίνει λόγος για λοιπές λεπτομέρειες υλοποίησης όπως τιμές αρχικοποίησης, τύπος βελτιστοποιητή (\en{optimizer}) κτλ.

\subsection{Αρχιτεκτονική Νευρωνικού Δικτύου}

Το βασικό μοντέλο που χρησιμοποιείται στην πλειοψηφία των πειραμάτων μας παρουσιάζεται στο σχήμα ... Αποτελείται από 3 επίπεδα εκ των οποίων τα πρώτα δύο είναι συνελικτικά (ονόματι \en{Conv1} και \en{PrimaryCaps}) και το τρίτο πλήρως διασυνδεδεμένο (επίπεδο \en{DigitCaps}). Πιο αναλυτικά, το επίπεδο \en{Conv1} έχει 256 πυρήνες συνέλιξης μεγέθους $9 \times 9$, βήμα (\en{stride}) ίσο με 1 και συνάρτηση ενεργοποίησης \en{ReLU}.\par

Αναφορικά με το επίπεδο \en{PrimaryCaps}, ο ρόλος του είναι αυτός των ανάστροφων γραφικών, όπως εξηγήσαμε στην ενότητα \ref{sec:capsule_theory}. Πρακτικά, αποτελεί ένα συνελικτικό επίπεδο με 32 κανάλια από 8\en{D} κάψουλες\textendash διανύσματα. Δηλαδή, κάθε κάψουλα περιέχει 8 μονάδες συνέλιξης με πυρήνες μεγέθους $9 \times 9$ και βήμα 2. Κατά αυτόν τον τρόπο, κάθε κάψουλα \textquote{βλέπει} $256 \times 9 \times 9$ στοιχεία (μονάδες) από τους χάρτες χαρακτηριστικών του προηγούμενου επιπέδου.\par

Όπως φαίνεται και από το σχετικό σχήμα, με αυτό το επίπεδο σχηματίζεται ένα πλέγμα από $32 \times 6 \times 6$ κάψουλες. Να σημειώσουμε ότι επειδή το επίπεδο \en{PrimaryCaps} αποτελεί ένα συνελικτικό επίπεδο από κάψουλες, τα βάρη των πυρήνων (κυλιόμενων παραθύρων) σε κάθε πλαίσιο στους άξονες $x-y$ $6 \times 6$ διαμοιράζονται. Η ειδοποιός διαφορά με ένα συνελικτικό επίπεδο χωρίς κάψουλες είναι στην συνάρτηση ενεργοποίησης. Αυτή αφενός είναι μια συνάρτηση σύνθλιψης (\en{squashing function}) που θα ορίσουμε στη συνέχεια και αφετέρου εφαρμόζεται σε ομάδες 8 στοιχείων τη φορά (δηλαδή σε κάθε 8\en{D} κάψουλα). Συνεπώς, το επίπεδο \en{PrimaryCaps} μπορεί να θεωρηθεί ως απλό συνελικτικό επίπεδο με $32 \times 8$ κανάλια στο οποίο, ανά ομάδες των 8 στοιχείων στη διάσταση βάθους, εφαρμόζεται μη γραμμικότητα τύπου \textquote{μπλοκ} (\en{block non\textendash linearity}).\par

Το τελευταίο επίπεδο είναι το \en{DigitCaps} το οποίο έχει σαν έξοδο (συνήθως 10) 16\en{D} κάψουλες\textendash διανύσματα των οποίων το μήκος ($L_2$ νόρμα), όπως έχουμε προαναφέρει, χρησιμοποιείται για τον εντοπισμό της κλάσης πρόβλεψης. Ανάμεσα στα πλήρως διασυνδεδεμένα επίπεδα \en{PrimaryCaps} και \en{DigitCaps} λαμβάνει χώρα ο αλγόριθμος δρομολόγησης μέσω συμφωνίας που αναλύουμε παρακάτω. Όπως φαίνεται και από το σχήμα, μεταξύ των δύο επιπέδων παρεμβάλλονται και μια σειρά από πίνακες βαρών ($6\times 6 \times 32 \times 10$ τέτοιοι πίνακες διάστασης $8 \times 16$) που μετασχηματίζουν τις τιμές της κάθε 8\en{D} κάψουλας του επιπέδου \en{PrimaryCaps} σε 16\en{D} ψήφους, μια για κάθε κάψουλα γονέα (άρα 10 ψήφοι αντιστοιχούν σε κάθε κάψουλα επιπέδου \en{PrimaryCaps}). Επισημαίνουμε ότι οι πίνακες βαρών τροποποιούνται κατά την εκπαίδευση και δεν εξαρτώνται από το εκάστοτε μεμονωμένο παράδειγμα (αποθηκεύουν πληροφορία μεταξύ μερών \textendash όλου που είναι ανεξάρτητη από την οπτική γωνία).

\begin{algorithm}
    \caption{An algorithm with caption}\label{alg:cap}
    \begin{algorithmic}
    \Require $n \geq 0$
    \Ensure $y = x^n$
    \State $y \gets 1$
    \State $X \gets x$
    \State $N \gets n$
    \While{$N \neq 0$}
    \If{$N$ is even}
        \State $X \gets X \times X$
        \State $N \gets \frac{N}{2}$  \Comment{This is a comment}
    \ElsIf{$N$ is odd}
        \State $y \gets y \times X$
        \State $N \gets N - 1$
    \EndIf
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
